"""
This script creates a video flying through a sequence of point clouds.
It loads PLY files generated by video_to_pointcloud.py and renders a fly-through animation.

Usage:
    python fly_through_pointcloud.py --input-dir ./vis_video_pointcloud/ply --output-video fly_through.mp4 --width 1280 --height 720

Arguments:
    --input-dir: Directory containing the PLY files
    --output-video: Path to save the output video
    --width: Width of the output video
    --height: Height of the output video
    --fps: Frames per second of the output video
    --trajectory: Type of camera trajectory (circle, line, or auto)
    --start-frame: First frame to include
    --end-frame: Last frame to include
    --point-size: Size of points in the visualization
"""

import argparse
import cv2
import glob
import numpy as np
import open3d as o3d
import os
import time
from tqdm import tqdm
import math


def get_camera_trajectory(trajectory_type, frame_count, center, radius=3.0):
    """
    Generate camera positions for the trajectory.
    
    Args:
        trajectory_type: Type of trajectory (circle, line, or auto)
        frame_count: Number of frames
        center: Center point of the scene
        radius: Radius of the circle trajectory
        
    Returns:
        List of camera positions
    """
    positions = []
    
    if trajectory_type == 'circle':
        # Circular trajectory around the center
        for i in range(frame_count):
            angle = 2 * math.pi * i / frame_count
            x = center[0] + radius * math.cos(angle)
            y = center[1] + radius * math.sin(angle)
            z = center[2] + radius * 0.3 * math.sin(angle * 2)  # Add some vertical movement
            positions.append([x, y, z])
    
    elif trajectory_type == 'line':
        # Linear trajectory from left to right
        start_pos = [center[0] - radius, center[1], center[2] + radius/2]
        end_pos = [center[0] + radius, center[1], center[2] + radius/2]
        
        for i in range(frame_count):
            t = i / (frame_count - 1)
            pos = [
                start_pos[0] + t * (end_pos[0] - start_pos[0]),
                start_pos[1] + t * (end_pos[1] - start_pos[1]),
                start_pos[2] + t * (end_pos[2] - start_pos[2])
            ]
            positions.append(pos)
    
    elif trajectory_type == 'auto':
        # Automatic trajectory that combines movements
        for i in range(frame_count):
            t = i / (frame_count - 1)
            angle = 2 * math.pi * t
            
            # Start with a slight zoom in, then circle around, then zoom out
            zoom_factor = 1.0 - 0.3 * math.sin(math.pi * t)
            
            x = center[0] + radius * zoom_factor * math.cos(angle)
            y = center[1] + radius * zoom_factor * math.sin(angle)
            z = center[2] + radius * 0.5 * math.sin(angle * 3)  # More vertical movement
            
            positions.append([x, y, z])
    
    return positions


def main():
    parser = argparse.ArgumentParser(description='Create a fly-through video of point clouds')
    parser.add_argument('--input-dir', type=str, required=True,
                        help='Directory containing PLY files')
    parser.add_argument('--output-video', type=str, default='fly_through.mp4',
                        help='Path to save the output video')
    parser.add_argument('--width', type=int, default=1280,
                        help='Width of the output video')
    parser.add_argument('--height', type=int, default=720,
                        help='Height of the output video')
    parser.add_argument('--fps', type=int, default=30,
                        help='Frames per second of the output video')
    parser.add_argument('--trajectory', type=str, default='auto',
                        choices=['circle', 'line', 'auto'],
                        help='Type of camera trajectory')
    parser.add_argument('--start-frame', type=int, default=0,
                        help='First frame to include')
    parser.add_argument('--end-frame', type=int, default=None,
                        help='Last frame to include')
    parser.add_argument('--point-size', type=float, default=2.0,
                        help='Size of points in the visualization')
    
    args = parser.parse_args()
    
    # Find all PLY files in the input directory
    ply_files = sorted(glob.glob(os.path.join(args.input_dir, '*.ply')))
    
    if not ply_files:
        print(f"No PLY files found in {args.input_dir}")
        return
    
    print(f"Found {len(ply_files)} PLY files")
    
    # Apply frame range limits
    start_idx = args.start_frame
    end_idx = args.end_frame if args.end_frame is not None else len(ply_files)
    ply_files = ply_files[start_idx:end_idx]
    
    print(f"Processing frames {start_idx} to {end_idx-1}")
    
    # Create a video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(args.output_video, fourcc, args.fps, (args.width, args.height))
    
    # Create a visualization window
    vis = o3d.visualization.Visualizer()
    vis.create_window(width=args.width, height=args.height, visible=False)
    
    # Set rendering options
    opt = vis.get_render_option()
    opt.point_size = args.point_size
    opt.background_color = np.array([0, 0, 0])  # Black background
    
    # Load the first point cloud to get scene bounds
    first_pcd = o3d.io.read_point_cloud(ply_files[0])
    vis.add_geometry(first_pcd)
    
    # Get the center of the scene
    center = first_pcd.get_center()
    
    # Estimate a good radius for the camera trajectory
    # based on the bounding box of the point cloud
    bbox = first_pcd.get_axis_aligned_bounding_box()
    bbox_extent = bbox.get_extent()
    radius = max(bbox_extent) * 1.5  # 1.5 times the largest dimension
    
    # Generate camera trajectory
    camera_positions = get_camera_trajectory(args.trajectory, len(ply_files), center, radius)
    
    # Set up the camera view
    view_control = vis.get_view_control()
    
    # Process each frame
    for i, ply_file in enumerate(tqdm(ply_files)):
        # Load the point cloud
        pcd = o3d.io.read_point_cloud(ply_file)
        
        # Remove the previous point cloud and add the new one
        vis.clear_geometries()
        vis.add_geometry(pcd)
        
        # Set camera position
        cam_pos = camera_positions[i]
        look_at = center
        up = [0, 0, 1]  # Z-up orientation
        
        view_control.set_lookat(look_at)
        view_control.set_front(np.array(cam_pos) - np.array(look_at))
        view_control.set_up(up)
        
        # Update the visualization
        vis.poll_events()
        vis.update_renderer()
        
        # Capture the frame
        image = vis.capture_screen_float_buffer(do_render=True)
        image_np = np.asarray(image) * 255
        image_np = image_np.astype(np.uint8)
        
        # Convert RGB to BGR for OpenCV
        image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        
        # Write the frame to the video
        video_writer.write(image_bgr)
    
    # Clean up
    vis.destroy_window()
    video_writer.release()
    
    print(f"Video saved to {args.output_video}")


if __name__ == '__main__':
    main() 
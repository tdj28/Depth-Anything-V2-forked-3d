"""
This script creates a video flying through a sequence of point clouds with smooth transitions.
It loads PLY files generated by video_to_pointcloud.py, interpolates between frames,
and renders a fly-through animation with advanced visual effects.

Usage:
    python fly_through_pointcloud_advanced.py --input-dir ./vis_video_pointcloud/ply --output-video fly_through_advanced.mp4

Arguments:
    --input-dir: Directory containing the PLY files
    --output-video: Path to save the output video
    --width: Width of the output video
    --height: Height of the output video
    --fps: Frames per second of the output video
    --trajectory: Type of camera trajectory (circle, line, auto, or orbit)
    --start-frame: First frame to include
    --end-frame: Last frame to include
    --point-size: Size of points in the visualization
    --frame-step: Process every Nth frame from the input directory
    --interpolation-frames: Number of frames to generate between each input frame
    --enable-effects: Enable visual effects like depth of field and ambient occlusion
"""

import argparse
import cv2
import glob
import numpy as np
import open3d as o3d
import os
import time
from tqdm import tqdm
import math
import random


def interpolate_point_clouds(pcd1, pcd2, t):
    """
    Interpolate between two point clouds.
    
    Args:
        pcd1: First point cloud
        pcd2: Second point cloud
        t: Interpolation factor (0 to 1)
        
    Returns:
        Interpolated point cloud
    """
    # Get points and colors from both point clouds
    points1 = np.asarray(pcd1.points)
    colors1 = np.asarray(pcd1.colors)
    points2 = np.asarray(pcd2.points)
    colors2 = np.asarray(pcd2.colors)
    
    # Interpolate points and colors
    points = points1 * (1 - t) + points2 * t
    colors = colors1 * (1 - t) + colors2 * t
    
    # Create a new point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)
    pcd.colors = o3d.utility.Vector3dVector(colors)
    
    return pcd


def get_camera_trajectory(trajectory_type, frame_count, center, radius=3.0):
    """
    Generate camera positions for the trajectory.
    
    Args:
        trajectory_type: Type of trajectory (circle, line, auto, or orbit)
        frame_count: Number of frames
        center: Center point of the scene
        radius: Radius of the circle trajectory
        
    Returns:
        List of camera positions and look-at points
    """
    positions = []
    look_at_points = []
    
    if trajectory_type == 'circle':
        # Circular trajectory around the center
        for i in range(frame_count):
            angle = 2 * math.pi * i / frame_count
            x = center[0] + radius * math.cos(angle)
            y = center[1] + radius * math.sin(angle)
            z = center[2] + radius * 0.3 * math.sin(angle * 2)  # Add some vertical movement
            positions.append([x, y, z])
            look_at_points.append(center)
    
    elif trajectory_type == 'line':
        # Linear trajectory from left to right
        start_pos = [center[0] - radius, center[1], center[2] + radius/2]
        end_pos = [center[0] + radius, center[1], center[2] + radius/2]
        
        for i in range(frame_count):
            t = i / (frame_count - 1)
            pos = [
                start_pos[0] + t * (end_pos[0] - start_pos[0]),
                start_pos[1] + t * (end_pos[1] - start_pos[1]),
                start_pos[2] + t * (end_pos[2] - start_pos[2])
            ]
            positions.append(pos)
            look_at_points.append(center)
    
    elif trajectory_type == 'orbit':
        # Orbit trajectory that moves around and changes elevation
        for i in range(frame_count):
            t = i / frame_count
            angle_horizontal = 2 * math.pi * t
            angle_vertical = 0.5 * math.pi * math.sin(math.pi * t)
            
            x = center[0] + radius * math.cos(angle_horizontal) * math.cos(angle_vertical)
            y = center[1] + radius * math.sin(angle_horizontal) * math.cos(angle_vertical)
            z = center[2] + radius * math.sin(angle_vertical)
            
            positions.append([x, y, z])
            
            # Look slightly ahead in the orbit
            look_ahead = 0.05
            angle_ahead = 2 * math.pi * (t + look_ahead)
            look_x = center[0] + (radius * 0.8) * math.cos(angle_ahead)
            look_y = center[1] + (radius * 0.8) * math.sin(angle_ahead)
            look_z = center[2]
            look_at_points.append([look_x, look_y, look_z])
    
    elif trajectory_type == 'auto':
        # Automatic trajectory that combines movements
        for i in range(frame_count):
            t = i / frame_count
            angle = 2 * math.pi * t
            
            # Start with a slight zoom in, then circle around, then zoom out
            zoom_factor = 1.0 - 0.3 * math.sin(math.pi * t)
            
            x = center[0] + radius * zoom_factor * math.cos(angle)
            y = center[1] + radius * zoom_factor * math.sin(angle)
            z = center[2] + radius * 0.5 * math.sin(angle * 3)  # More vertical movement
            
            positions.append([x, y, z])
            
            # Dynamic look-at point that moves slightly
            look_x = center[0] + radius * 0.2 * math.cos(angle * 2)
            look_y = center[1] + radius * 0.2 * math.sin(angle * 3)
            look_z = center[2] + radius * 0.1 * math.sin(angle * 4)
            look_at_points.append([look_x, look_y, look_z])
    
    return positions, look_at_points


def apply_visual_effects(vis):
    """
    Apply advanced visual effects to the visualization.
    
    Args:
        vis: Open3D visualizer
    """
    render_option = vis.get_render_option()
    
    # Enable ambient occlusion for better depth perception
    render_option.point_size = 2.0
    render_option.light_on = True
    render_option.mesh_shade_option = o3d.visualization.MeshShadeOption.SMOOTH
    
    # Try to enable advanced rendering features if available
    try:
        # These might not be available in all Open3D versions
        render_option.enable_anti_aliasing = True
        render_option.enable_depth_of_field = True
        render_option.focal_distance = 10.0
        render_option.focal_range = 5.0
    except:
        pass


def main():
    parser = argparse.ArgumentParser(description='Create a fly-through video of point clouds with smooth transitions')
    parser.add_argument('--input-dir', type=str, required=True,
                        help='Directory containing PLY files')
    parser.add_argument('--output-video', type=str, default='fly_through_advanced.mp4',
                        help='Path to save the output video')
    parser.add_argument('--width', type=int, default=1280,
                        help='Width of the output video')
    parser.add_argument('--height', type=int, default=720,
                        help='Height of the output video')
    parser.add_argument('--fps', type=int, default=30,
                        help='Frames per second of the output video')
    parser.add_argument('--trajectory', type=str, default='auto',
                        choices=['circle', 'line', 'auto', 'orbit'],
                        help='Type of camera trajectory')
    parser.add_argument('--start-frame', type=int, default=0,
                        help='First frame to include')
    parser.add_argument('--end-frame', type=int, default=None,
                        help='Last frame to include')
    parser.add_argument('--point-size', type=float, default=2.0,
                        help='Size of points in the visualization')
    parser.add_argument('--frame-step', type=int, default=1,
                        help='Process every Nth frame from the input directory')
    parser.add_argument('--interpolation-frames', type=int, default=2,
                        help='Number of frames to generate between each input frame')
    parser.add_argument('--enable-effects', action='store_true',
                        help='Enable visual effects like depth of field and ambient occlusion')
    
    args = parser.parse_args()
    
    # Find all PLY files in the input directory
    ply_files = sorted(glob.glob(os.path.join(args.input_dir, '*.ply')))
    
    if not ply_files:
        print(f"No PLY files found in {args.input_dir}")
        return
    
    print(f"Found {len(ply_files)} PLY files")
    
    # Apply frame step to reduce the number of input frames
    ply_files = ply_files[::args.frame_step]
    
    # Apply frame range limits
    start_idx = args.start_frame
    end_idx = args.end_frame if args.end_frame is not None else len(ply_files)
    ply_files = ply_files[start_idx:end_idx]
    
    print(f"Processing {len(ply_files)} frames after applying frame step and range limits")
    
    # Calculate total number of frames in the output video
    total_frames = (len(ply_files) - 1) * (args.interpolation_frames + 1) + 1
    print(f"Output video will have {total_frames} frames")
    
    # Create a video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(args.output_video, fourcc, args.fps, (args.width, args.height))
    
    # Create a visualization window
    vis = o3d.visualization.Visualizer()
    vis.create_window(width=args.width, height=args.height, visible=False)
    
    # Set rendering options
    opt = vis.get_render_option()
    opt.point_size = args.point_size
    opt.background_color = np.array([0, 0, 0])  # Black background
    
    if args.enable_effects:
        apply_visual_effects(vis)
    
    # Load all point clouds
    print("Loading point clouds...")
    point_clouds = []
    for ply_file in tqdm(ply_files):
        pcd = o3d.io.read_point_cloud(ply_file)
        point_clouds.append(pcd)
    
    # Get the center of the scene from the first point cloud
    center = point_clouds[0].get_center()
    
    # Estimate a good radius for the camera trajectory
    bbox = point_clouds[0].get_axis_aligned_bounding_box()
    bbox_extent = bbox.get_extent()
    radius = max(bbox_extent) * 1.5  # 1.5 times the largest dimension
    
    # Generate camera trajectory
    camera_positions, look_at_points = get_camera_trajectory(
        args.trajectory, total_frames, center, radius
    )
    
    # Set up the camera view
    view_control = vis.get_view_control()
    
    # Process each frame with interpolation
    frame_idx = 0
    
    print("Rendering frames...")
    with tqdm(total=total_frames) as pbar:
        # Add the first point cloud
        vis.add_geometry(point_clouds[0])
        
        for i in range(len(point_clouds) - 1):
            # Get the current and next point clouds
            pcd_current = point_clouds[i]
            pcd_next = point_clouds[i + 1]
            
            # Render the current point cloud
            vis.update_geometry(pcd_current)
            
            # Set camera position for the current frame
            cam_pos = camera_positions[frame_idx]
            look_at = look_at_points[frame_idx]
            up = [0, 0, 1]  # Z-up orientation
            
            view_control.set_lookat(look_at)
            view_control.set_front(np.array(cam_pos) - np.array(look_at))
            view_control.set_up(up)
            
            # Update the visualization
            vis.poll_events()
            vis.update_renderer()
            
            # Capture the frame
            image = vis.capture_screen_float_buffer(do_render=True)
            image_np = np.asarray(image) * 255
            image_np = image_np.astype(np.uint8)
            
            # Convert RGB to BGR for OpenCV
            image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
            
            # Write the frame to the video
            video_writer.write(image_bgr)
            frame_idx += 1
            pbar.update(1)
            
            # Generate interpolated frames
            for j in range(args.interpolation_frames):
                # Calculate interpolation factor
                t = (j + 1) / (args.interpolation_frames + 1)
                
                # Interpolate between current and next point clouds
                pcd_interp = interpolate_point_clouds(pcd_current, pcd_next, t)
                
                # Update the geometry
                vis.clear_geometries()
                vis.add_geometry(pcd_interp)
                
                # Set camera position for the interpolated frame
                cam_pos = camera_positions[frame_idx]
                look_at = look_at_points[frame_idx]
                
                view_control.set_lookat(look_at)
                view_control.set_front(np.array(cam_pos) - np.array(look_at))
                view_control.set_up(up)
                
                # Update the visualization
                vis.poll_events()
                vis.update_renderer()
                
                # Capture the frame
                image = vis.capture_screen_float_buffer(do_render=True)
                image_np = np.asarray(image) * 255
                image_np = image_np.astype(np.uint8)
                
                # Convert RGB to BGR for OpenCV
                image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                
                # Write the frame to the video
                video_writer.write(image_bgr)
                frame_idx += 1
                pbar.update(1)
        
        # Add the last frame
        vis.clear_geometries()
        vis.add_geometry(point_clouds[-1])
        
        # Set camera position for the last frame
        cam_pos = camera_positions[frame_idx]
        look_at = look_at_points[frame_idx]
        
        view_control.set_lookat(look_at)
        view_control.set_front(np.array(cam_pos) - np.array(look_at))
        view_control.set_up(up)
        
        # Update the visualization
        vis.poll_events()
        vis.update_renderer()
        
        # Capture the frame
        image = vis.capture_screen_float_buffer(do_render=True)
        image_np = np.asarray(image) * 255
        image_np = image_np.astype(np.uint8)
        
        # Convert RGB to BGR for OpenCV
        image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        
        # Write the frame to the video
        video_writer.write(image_bgr)
        pbar.update(1)
    
    # Clean up
    vis.destroy_window()
    video_writer.release()
    
    print(f"Video saved to {args.output_video}")


if __name__ == '__main__':
    main() 